D:\softwares\anaconda3\envs\RGAT20230627\python.exe "D:\softwares\Pycharm\PyCharm Community Edition 2022.1.3\plugins\python-ce\helpers\pydev\pydevd.py" --multiprocess --qt-support=auto --client 127.0.0.1 --port 9135 --file F:/Code/240313/gat/graph/gcn_gat_link/main_mydata.py
Connected to pydev debugger (build 221.5921.27)
Loading zh dataset...
D:\softwares\anaconda3\envs\RGAT20230627\lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead
  warnings.warn(out)
Epoch: 001, Loss: 0.6829, Val: 0.5733, Test: 0.5308
Epoch: 002, Loss: 0.6777, Val: 0.5446, Test: 0.5308
Epoch: 003, Loss: 0.7086, Val: 0.6747, Test: 0.6138
Epoch: 004, Loss: 0.6649, Val: 0.5100, Test: 0.6138
Epoch: 005, Loss: 0.6760, Val: 0.4754, Test: 0.6138
Epoch: 006, Loss: 0.6691, Val: 0.6544, Test: 0.6138
Epoch: 007, Loss: 0.6558, Val: 0.6198, Test: 0.6138
Epoch: 008, Loss: 0.6525, Val: 0.6057, Test: 0.6138
Epoch: 009, Loss: 0.6537, Val: 0.5792, Test: 0.6138
Epoch: 010, Loss: 0.6268, Val: 0.6414, Test: 0.6138
Epoch: 011, Loss: 0.6118, Val: 0.6566, Test: 0.6138
Epoch: 012, Loss: 0.6251, Val: 0.5814, Test: 0.6138
Epoch: 013, Loss: 0.6127, Val: 0.5863, Test: 0.6138
Epoch: 014, Loss: 0.5958, Val: 0.5760, Test: 0.6138
Epoch: 015, Loss: 0.5856, Val: 0.5873, Test: 0.6138
Epoch: 016, Loss: 0.5890, Val: 0.5749, Test: 0.6138
Epoch: 017, Loss: 0.5754, Val: 0.5928, Test: 0.6138
Epoch: 018, Loss: 0.5826, Val: 0.5890, Test: 0.6138
Epoch: 019, Loss: 0.5854, Val: 0.5944, Test: 0.6138
Epoch: 020, Loss: 0.5851, Val: 0.6036, Test: 0.6138
Epoch: 021, Loss: 0.5891, Val: 0.6236, Test: 0.6138
Epoch: 022, Loss: 0.5768, Val: 0.6171, Test: 0.6138
Epoch: 023, Loss: 0.5737, Val: 0.5906, Test: 0.6138
Epoch: 024, Loss: 0.5825, Val: 0.5911, Test: 0.6138
Epoch: 025, Loss: 0.5834, Val: 0.5825, Test: 0.6138
Epoch: 026, Loss: 0.5765, Val: 0.6003, Test: 0.6138
Epoch: 027, Loss: 0.5611, Val: 0.6203, Test: 0.6138
Epoch: 028, Loss: 0.5695, Val: 0.6339, Test: 0.6138
Epoch: 029, Loss: 0.5761, Val: 0.6485, Test: 0.6138
Epoch: 030, Loss: 0.5638, Val: 0.5819, Test: 0.6138
Epoch: 031, Loss: 0.5776, Val: 0.5787, Test: 0.6138
Epoch: 032, Loss: 0.5798, Val: 0.5873, Test: 0.6138
Epoch: 033, Loss: 0.5653, Val: 0.6025, Test: 0.6138
Epoch: 034, Loss: 0.5719, Val: 0.6182, Test: 0.6138
Epoch: 035, Loss: 0.5696, Val: 0.6387, Test: 0.6138
Epoch: 036, Loss: 0.5775, Val: 0.6836, Test: 0.7370
Epoch: 037, Loss: 0.5615, Val: 0.6733, Test: 0.7370
Epoch: 038, Loss: 0.5632, Val: 0.6263, Test: 0.7370
Epoch: 039, Loss: 0.5702, Val: 0.6128, Test: 0.7370
Epoch: 040, Loss: 0.5697, Val: 0.6079, Test: 0.7370
Epoch: 041, Loss: 0.5641, Val: 0.6236, Test: 0.7370
Epoch: 042, Loss: 0.5598, Val: 0.6598, Test: 0.7370
Epoch: 043, Loss: 0.5523, Val: 0.6674, Test: 0.7370
Epoch: 044, Loss: 0.5542, Val: 0.6539, Test: 0.7370
Epoch: 045, Loss: 0.5568, Val: 0.6387, Test: 0.7370
Epoch: 046, Loss: 0.5511, Val: 0.6263, Test: 0.7370
Epoch: 047, Loss: 0.5571, Val: 0.6079, Test: 0.7370
Epoch: 048, Loss: 0.5447, Val: 0.6063, Test: 0.7370
Epoch: 049, Loss: 0.5620, Val: 0.5955, Test: 0.7370
Epoch: 050, Loss: 0.5638, Val: 0.6441, Test: 0.7370
Epoch: 051, Loss: 0.5524, Val: 0.6452, Test: 0.7370
Epoch: 052, Loss: 0.5356, Val: 0.6409, Test: 0.7370
Epoch: 053, Loss: 0.5527, Val: 0.6295, Test: 0.7370
Epoch: 054, Loss: 0.5845, Val: 0.6090, Test: 0.7370
Epoch: 055, Loss: 0.5442, Val: 0.5884, Test: 0.7370
Epoch: 056, Loss: 0.5627, Val: 0.5884, Test: 0.7370
Epoch: 057, Loss: 0.5535, Val: 0.6312, Test: 0.7370
Epoch: 058, Loss: 0.5387, Val: 0.6349, Test: 0.7370
Epoch: 059, Loss: 0.5481, Val: 0.6393, Test: 0.7370
Epoch: 060, Loss: 0.5261, Val: 0.6241, Test: 0.7370
Epoch: 061, Loss: 0.5485, Val: 0.6144, Test: 0.7370
Epoch: 062, Loss: 0.5550, Val: 0.6036, Test: 0.7370
Epoch: 063, Loss: 0.5483, Val: 0.6230, Test: 0.7370
Epoch: 064, Loss: 0.5416, Val: 0.6409, Test: 0.7370
Epoch: 065, Loss: 0.5377, Val: 0.6501, Test: 0.7370
Epoch: 066, Loss: 0.5397, Val: 0.6328, Test: 0.7370
Epoch: 067, Loss: 0.5290, Val: 0.6111, Test: 0.7370
Epoch: 068, Loss: 0.5380, Val: 0.6138, Test: 0.7370
Epoch: 069, Loss: 0.5709, Val: 0.6209, Test: 0.7370
Epoch: 070, Loss: 0.5436, Val: 0.6349, Test: 0.7370
Epoch: 071, Loss: 0.5353, Val: 0.6425, Test: 0.7370
Epoch: 072, Loss: 0.5528, Val: 0.6685, Test: 0.7370
Epoch: 073, Loss: 0.5476, Val: 0.6598, Test: 0.7370
Epoch: 074, Loss: 0.5304, Val: 0.6479, Test: 0.7370
Epoch: 075, Loss: 0.5231, Val: 0.6458, Test: 0.7370
Epoch: 076, Loss: 0.5293, Val: 0.6425, Test: 0.7370
Epoch: 077, Loss: 0.5371, Val: 0.6431, Test: 0.7370
Epoch: 078, Loss: 0.5340, Val: 0.6322, Test: 0.7370
Epoch: 079, Loss: 0.5230, Val: 0.6301, Test: 0.7370
Epoch: 080, Loss: 0.5384, Val: 0.6436, Test: 0.7370
Epoch: 081, Loss: 0.5299, Val: 0.6436, Test: 0.7370
Epoch: 082, Loss: 0.5340, Val: 0.6506, Test: 0.7370
Epoch: 083, Loss: 0.5269, Val: 0.6420, Test: 0.7370
Epoch: 084, Loss: 0.5446, Val: 0.6360, Test: 0.7370
Epoch: 085, Loss: 0.5326, Val: 0.6263, Test: 0.7370
Epoch: 086, Loss: 0.5284, Val: 0.6214, Test: 0.7370
Epoch: 087, Loss: 0.5388, Val: 0.6398, Test: 0.7370
Epoch: 088, Loss: 0.5278, Val: 0.6436, Test: 0.7370
Epoch: 089, Loss: 0.5253, Val: 0.6366, Test: 0.7370
Epoch: 090, Loss: 0.5306, Val: 0.6339, Test: 0.7370
Epoch: 091, Loss: 0.5321, Val: 0.6328, Test: 0.7370
Epoch: 092, Loss: 0.5324, Val: 0.6322, Test: 0.7370
Epoch: 093, Loss: 0.5062, Val: 0.6366, Test: 0.7370
Epoch: 094, Loss: 0.5133, Val: 0.6555, Test: 0.7370
Epoch: 095, Loss: 0.5327, Val: 0.6668, Test: 0.7370
Epoch: 096, Loss: 0.5193, Val: 0.6614, Test: 0.7370
Epoch: 097, Loss: 0.5347, Val: 0.6474, Test: 0.7370
Epoch: 098, Loss: 0.5219, Val: 0.6533, Test: 0.7370
Epoch: 099, Loss: 0.5395, Val: 0.6544, Test: 0.7370
Epoch: 100, Loss: 0.5226, Val: 0.6517, Test: 0.7370
